ANA HATLARIYLA TAKÄ°P EDÄ°LECEK SÄ°STEMâœ…:
(EÄŸitim dosyalarÄ±nda tekrar eden bulmacalarÄ±n kontrolÃ¼ yapÄ±lacak ve fazlalÄ±klar silinecek, burasÄ± notebook oluÅŸturmadan evvel yapÄ±lacak, yarÄ±ÅŸmaya gÃ¶nderirken bu aÅŸamaya gerek olmayacak.)
1- Ana bulmaca dosyasÄ± her ana bulmaca ayrÄ± klasÃ¶rde olup her klasÃ¶r tek bulmacanÄ±n girdi, Ã§Ä±ktÄ± ve testlerini ihtiva edecek ÅŸekilde dÃ¼zenlenecek.

3-Bulmaca,numpy matrisi yazdÄ±racak ÅŸekilde py dosyasÄ±na,satÄ±r-sÃ¼tun her ikisinin de dizilerini bÃ¼tÃ¼n olarak gÃ¶rmeyi saÄŸlayan yeni json formatÄ±na ve png'ye Ã§evrilecek.(ilk bulmacalarÄ± Ã§evirmek iÃ§in olan hÃ¼creler hazÄ±rlandÄ±, Ã¼retilenler sonradan Ã§evrilecek)



5- Bulmacalar Ã§Ã¶zÃ¼lmeye baÅŸlanacaktÄ±r. Embeddingci Rag'a kaydedilecek her ÅŸeyi vektÃ¶rleÅŸtirir. 2 motor vardÄ±r. Birisi kod kombinasyoncusu, biri ihtimal hesapÃ§Ä±sÄ±. kodcu olan motor belli gramerlere, llm tarafÄ±ndan ifade edilecek kÄ±sÄ±tlamalara gÃ¶re kod kombinasyonlarÄ± Ã¼retir. Her Ã¼rettiÄŸi kod bir formÃ¼le gÃ¶re puanlanÄ±r. Fazla puan alan kodlara benzer kodlar daha Ã§ok Ã¼retilir. (formÃ¼l daha sonra sÃ¶ylenecektir) ihtimal motoru ise farklÄ± matris kombinasyonlarÄ± Ã¼reten, her tÃ¼rlÃ¼ durumu ihtimaller ile belirtmeye yarayan Ã§ok fonksiyonlu bir cihazdÄ±r. Mesela deÄŸiÅŸim tipleri adlÄ± kÃ¼mede 5 eleman varsa rag tablosuna doldurulacak tiplerin tekli, Ã§iftli, 2'den Ã§ok Ã§eÅŸitleri vardÄ±r. Bu motor toplam ihtimal sayÄ±sÄ±nÄ±, her bir elemanÄ±n yerleÅŸme ihtimalini hesaplar. Lakin salt bir ihtimal hesabÄ± deÄŸildir, bazÄ± elemanlar kesinlikle olmayacak olabilir. Bu yÃ¼zden katsayÄ±larÄ± llm tarafÄ±ndan belirlenecek umumi bir fonksiyon yazÄ±lÄ±r.2 elemanÄ±mÄ±z daha vardÄ±r:1-qwen 3 embedding 4B (RAG iÃ§in) 2-qwen3 vl-8B-thinking(ana Ã§Ã¶zÃ¼cÃ¼) Bu model batch'ler halinde kullanÄ±lacaktÄ±r. Her batch farklÄ± bir vazifelidir. Vazifeler: Ana Ã§Ã¶zÃ¼cÃ¼, haberci, mÃ¼nekkit, mÃ¼eddib, ihtimalci, kodcu, kaynak idarecisi. 
6- Ã‡Ã¶zÃ¼cÃ¼ bulmacadan Ã§Ä±karttÄ±ÄŸÄ± Ã¶zellikleri sql tablosuna kaydeder.
7- Bu Ã¶zellikleri Ã§Ä±kartÄ±rkenki mesnetlerini zikreder.
8- mesnetleri
12-Dsl kural havuzundan veya kendi istediÄŸi kod parÃ§alarÄ±yla kuralÄ± oluÅŸturan fonksiyonu(sadece onu, kÃ¼tÃ¼phane ve diÄŸer ÅŸeyler deÄŸil) yazar. Havuzda olmadan yazdÄ±ÄŸÄ± parÃ§acÄ±klar havuza fonksiyon olarak dahil edilir.
13-KÃ¼tÃ¼phaneler ve gerekli diÄŸer kodlar ile fonksiyonu tamamlar ve kodu Ã§alÄ±ÅŸtÄ±rÄ±r.
14-Netice tamamen doÄŸruysa kural doÄŸru tespit edilmiÅŸ demektir. Emin olmak iÃ§in bu sefer de Ã§Ä±ktÄ±dan girdiye doÄŸru olan kuralÄ±n bunun tam tersi olmasÄ± gerektiÄŸine binaen ters fonksiyon tanÄ±mlanÄ±r, kÃ¼tÃ¼phane ve diÄŸer elemanlar tamamlanÄ±r ve kod tatbik edilince girdiye doÄŸru ÅŸekilde ulaÅŸÄ±lÄ±p ulaÅŸÄ±lamadÄ±ÄŸÄ± tetkik edilir. DoÄŸruysa kural doÄŸru demektir. DeÄŸilse iki ihtimal vardÄ±r: ya ters alma iÅŸlemi hatalÄ±dÄ±r yahut kural bozuktur. Ters alma iÅŸlemi tekrar teftiÅŸ edilince yine dÃ¼zelmezse bu kural ikinci cevabÄ± oluÅŸturmak iÃ§in saklanÄ±r, asÄ±l kural aranmaya devam edilir.
15-Hem yukarÄ±da iÅŸaret olunmayan adÄ±mlarda hem de ÅŸimdi geÃ§erli olmak Ã¼zere eÄŸer netice kÄ±smen doÄŸruysa doÄŸru olan hÃ¼creler iÅŸaretlenir ve hatalÄ±larÄ±n Ã¼zerine yeniden murakabe yapÄ±lÄ±r(reasoning devri).
16-Kural tespit edilemiyorsa ve namzet kurallar oluÅŸmuÅŸsa iÃ§lerinden en doÄŸru olanlarÄ± sÄ±raya konulup test bulmacasÄ±ndan bu sÄ±ralamayÄ± bozacak aksi bir intiba alÄ±nmadÄ±kÃ§a ilk iki sÄ±radaki kural tatbikat iÃ§in seÃ§ilir.
17-Namzet kurallar da oluÅŸmamÄ±ÅŸsa  iki adÄ±m uygulanÄ±r: A-llm'lere dreamcoder motoru verilir. llm'ler bu motor Ã¼zerinde Ã§eÅŸitli parametreleri hassaslaÅŸtÄ±rarak veya kendileri arama sahasÄ±nÄ± mantÄ±klÄ± ÅŸekilde daraltacak ÅŸekilde motora yeni kodlar ilave ederek motoru Ã§alÄ±ÅŸtÄ±rÄ±r ve her Ã¼retilen kodda motoru durdurup Ã§Ä±ktÄ±sÄ±nÄ± teftiÅŸ eder ve akÄ±llarÄ±na bir ÅŸey gelinceye kadar bu ÅŸekilde devam eder. Bu 14. adÄ±ma tÃ¼m bulmacalar Ã¼zerinde uÄŸraÅŸÄ±lmÄ±ÅŸ olunduktan sonra geÃ§ilir, Ã¶nce tatbik edilmeyip kural bulunamayÄ±nca Ã¶bÃ¼r bulmacaya atlanÄ±lÄ±r. TÃ¼m vakit 12 saati geÃ§emez, Bu yÃ¼zden her bulmaca iÃ§in sayaÃ§ tutulur. Her bulmaca iÃ§in ayrÄ±lan sÃ¼re iÃ§inde ne kadar iÅŸ yapÄ±labilmiÅŸse onlar kaydedilir, geriye iÅŸ kalmÄ±ÅŸsa not bÄ±rakÄ±lÄ±p devam edilir, oyalanÄ±lmaz.
B- YÃ¼klenilen modellerden biri o an iÃ§in vram'den kaldÄ±rÄ±lÄ±p yer aÃ§Ä±lÄ±r ve baÅŸka bir yapay zekadan takÄ±lÄ± kalÄ±nan adÄ±mla ilgili ne Ã§Ã¶zÃ¼m Ã¼retmesi istenir. TÃ¼m kayÄ±t ve dosyalar da verilir, bu yÃ¼zden contexti uzun olmasÄ± yeÄŸdir. Veyahut bu kayÄ±tlar zaten Rag formatÄ±na Ã§evrilip veritabanÄ± ÅŸeklinde sunulup inference'ler bununla besleneceÄŸi iÃ§in contexti kÃ¼Ã§Ã¼k ama daha zeki bir model de tercihe ÅŸayan olabilir.
18-Her tatbikat submission.json yani yarÄ±ÅŸma platformunun istediÄŸi formatta kaydedilir.

NOT: LLM inference'leri vram'i doldurmadÄ±ÄŸÄ± mÃ¼ddetÃ§e ve multi-head biÃ§iminde ve tedbir payÄ± hariÃ§ vram'i azami kullanacak sayÄ±da yapÄ±lÄ±r.
NOT: EÄŸer bir inference baÅŸka bir inference'ten gelen cevabÄ± gerektiriyorsa onlar ayrÄ±lÄ±r, gerektirmeyenler batch'e dahil edilir.
NOT: Llm'lere Ã§Ä±ktÄ±larÄ±nÄ±n kendi karar verecekleri kÄ±sÄ±mlarÄ±nÄ± belli bir yapÄ±da etiketlerle iÅŸaretlemeleri sÃ¶ylenir. Bu iÅŸaretlemenin ne iÅŸe yarayacaÄŸÄ±nÄ± onlar fikretmiÅŸtir. Parser kodumuz tool olarak onlara verilir ve eÄŸer kodumuzda olmayan bir etiket veya etiket yapÄ±sÄ± varsa llm tarafÄ±ndan uygun ÅŸekilde gÃ¼ncellenir. Bu sayede proje akÄ±ÅŸÄ±nda llm bizzat mesuliyet alÄ±r.
NOT: Ãœstteki notun gerektirdiÄŸi gibi ana dosyadan farklÄ±, llm'lere prompt verme kodu da araÃ§ olarak tanÄ±mlanÄ±r. LLM, kendisine veya takÄ±m arkadaÅŸÄ±na verilecek promotlarÄ±, batch sayÄ±sÄ±nÄ± projeye en uygun ÅŸekilde dÃ¼zenler.Kod iÃ§inde read-only ve read-write kÄ±sÄ±mlarÄ± vardÄ±r, llm'ler yazma salahiyetleri olan yerlere yeni kodlar ilave edebilir veyahut kendisi tamamen ayrÄ± bir dosya oluÅŸturup eski koda kÃ¼tÃ¼phane olarak ekleyebilir. KodlarÄ±n zararlÄ± olup olmadÄ±ÄŸÄ±nÄ± mÃ¼nekkit Llm teftiÅŸ edecektir.
NOT: LLM'lere prompt metninde mesajÄ±n baÅŸÄ±nda tahminen kaÃ§ token yazacaklarÄ±nÄ± sÃ¶ylemeleri istenir. Yani bu da bir etikettirğŸ˜‰. Bu token sayÄ±sÄ±na; gpu,vram,ram,cpu gibi aksamlarÄ±n anlÄ±k durumuna gÃ¶re tahmini sÃ¼re hesaplanÄ±r.AynÄ± bunun gibi tÃ¼m adÄ±mlarda tahmini sÃ¼re hesaplanÄ±p iÅŸlemin devam edip etmeyeceÄŸi buna ve ayrÄ±labilecek azami sÃ¼reye gÃ¶re karar verilir.
NOT: LLM'lerin Ã§Ä±ktÄ±larÄ±nÄ± gÃ¶sterdikleri terminal akÄ±ÅŸÄ± kapatÄ±lÄ±r, onun yerine dosyalar olarak muhafaza edilir. Bu sayede gereksiz gecikmeler yok edilip teftiÅŸler dosyalar Ã¼zerinden saÄŸlanÄ±r. Llm'ler ilk oluÅŸturulmuÅŸ promptlara dokunamaz, onlar itina ile yazÄ±lmÄ±ÅŸtÄ±r. Lakin eÄŸer ihtiyaÃ§ duyarsa kendi kendisine veya bir baÅŸka llm'e verilmesi iÃ§in bir prompt hazÄ±rlayabilir, etiketiyle sunduÄŸu ve kodunu yazdÄ±ÄŸÄ± zaman Ã§alÄ±ÅŸtÄ±rÄ±labilir. LLM
NOT: Herhangi bir arÄ±zada kodun Ã§alÄ±ÅŸmaya kaldÄ±ÄŸÄ± yerden devam edebilmesi iÃ§in dosya tabanlÄ± checkpoint sistemi kullanÄ±lÄ±r. Her fonskiyon, her Ã§aÄŸrÄ± bir checkpoint olarak tutulur ve Ã§alÄ±ÅŸma bozulup yeniden baÅŸladÄ±ÄŸÄ± zaman evvela sistemin unuttuÄŸu ÅŸeyler geri hatÄ±rlatÄ±lÄ±r ve kalÄ±nan yerden devam edilir. Bunun iÃ§in bizzat arÄ±za durumlarÄ± iÃ§in tedbiren hazÄ±rlanmÄ±ÅŸ bir arÄ±za.py dosyasÄ± bulunur.
NOT: Dosyalar, deÄŸiÅŸkenler, llm Ã§Ä±ktÄ±larÄ± gibi neticeleri arÄ±zalara karÅŸÄ± tedbiren yeniden oluÅŸturma kalÄ±p kodu yazÄ±lÄ±r. 
NOT: Vakit sayacÄ± ilerledikÃ§e sisteme eksi puan olarak iÅŸler. Azami puan 100 olmasÄ±na raÄŸmen bulmaca Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±lÄ±rken puan dÃ¼ÅŸÃ¼p llm'lerin kafasÄ± karÄ±ÅŸmasÄ±n diye 100'den fazla bir deÄŸerden baÅŸlayÄ±p saniyeler ilerledikÃ§e belli seviyede azalÄ±r. 6 dakikanÄ±n sonunda 10 puana dÃ¼ÅŸÃ¼lÃ¼r. EÄŸer Ã§Ã¶zÃ¼lememiÅŸse ikinci dÃ¶nÃ¼ÅŸte 10'dan dÃ¼ÅŸmeye devam eder.
NOT: LLM'in prompt Ã¼retmek iÃ§in ÅŸevk katsayÄ±sÄ± vardÄ±r. Bu sayÄ± bir mevzu hakkÄ±nda ne kadar fazlaysa llm o konu hakkÄ±nda o kadar Ã§ok Ã§Ä±ktÄ± Ã¼retmeli ve Ã§Ä±ktÄ±larÄ±n devamÄ±nÄ± saÄŸlamak iÃ§in promptlar da Ã¼retmelidir. KatsayÄ±yÄ± yÃ¼kseltmenin ÅŸartlarÄ± ÅŸunlardÄ±r: EÄŸer bir istek henÃ¼z yerine getirilememiÅŸse, 




NOT: Mucitlikte kuluÃ§ka anÄ± diye bir tabir vardÄ±r. Biz bunu kendi sistemimizde temsil edeceÄŸiz. TÃ¼m bulmacalar gÃ¶zden geÃ§irildikten ve muhtemel kombinasyonlar llm'e gÃ¶sterildiÄŸi zaman llm'ler muhakeme devrine baÅŸlar. Ã‡Ä±ktÄ± Ã¼retmeden, arka planda sÃ¼rekli dÃ¼ÅŸÃ¼nÃ¼r. DÃ¼ÅŸÃ¼nÃ¼p delile dayandÄ±rarak net ÅŸekilde emin olduÄŸu tespitleri rag sistemine kaydedilir, emin olmadÄ±klarÄ± Ã¼zerinden dÃ¼ÅŸÃ¼nmeye devam eder.Bu devrin ne kadar sÃ¼receÄŸi kalan sÃ¼reye baÄŸlÄ±dÄ±r, belli bir noktadan sonra muhakeme durdurulup Ã§Ä±kan neticeler yeniden kendisine verilir ve Ã§Ä±ktÄ±yÄ± Ã¼retmesi beklenir.
NOT: Tek bir llm kullanmak da gayet mÃ¼mkÃ¼ndÃ¼r. Ä°kinci llm'in yapacaÄŸÄ± mÃ¼nekkitlik vazifesini aynÄ± llm farklÄ± batchlerde yapabilir. Mesela ilk 5 batch'de sorular reasoning(bundan sonra muhakeme namÄ±yla anÄ±lacak) devriyle cevaplanÄ±rken ikinci 5'lik devirde bu cevaplar, akÄ±l yÃ¼rÃ¼tmeler yani kÄ±sacasÄ± her ÅŸey tenkide tabi tutulur.



NOT: GPU, cpu gibi sistemlerin ne zaman kullanacaÄŸÄ± iyi bir ÅŸekilde planlanÄ±r. Her donanÄ±m her ÅŸey iÃ§in kullanÄ±lmaz.


NOT: DonanÄ±mlardan azami seviyede istifade edebilmek iÃ§in model kÃ¼Ã§Ã¼ltme haricindeki torch_inference, with torch.no_grad(), DataCollatorWithPadding, flash_attention_2, OpenBLAS, asyncio, deepseed, fsdp, onnx runtime ve tensor rt isimli optimizasyon kÃ¼tÃ¼phaneleri, araÃ§larÄ±, parametreleri vesaireden azami derecede faydalanÄ±lÄ±r.(ilk yÃ¼kleme iÃ§in hazÄ±r durumda, doÄŸruluÄŸu tetkik edilmeli)




NOT: Matris tipinden ayrÄ±lmamalÄ±, renkler ÅŸunlar dÄ±ÅŸÄ±nda bir ÅŸey olmamalÄ±, Ã§Ä±ktÄ± Ä±zgarasÄ± girdi Ä±zgarasÄ±nÄ±n iÃ§inden bir parÃ§a olabilir, aynÄ± ebatta olabilir gibi Ã§eÅŸitli kurallar tanÄ±mlar ve python kodunu yazarÄ±z, llm'in verdiÄŸi Ã§Ä±ktÄ± bunlara aykÄ±rÄ±ysa llm'e bir daha Ã¼retim yapmasÄ± gerektiÄŸi sÃ¶ylenir.
NOT: LLM bulmacadaki kuralÄ± tespit etse de etmese de mutlaka aynÄ± kalmasÄ± gereken tipteki hÃ¼creleri belirler. Bunu test bulmacasÄ± iÃ§in de yaptÄ±ktan sonra kalan hÃ¼crelerin tÃ¼m kombinasyonlarÄ± gpu'da numpy matris olarak hesaplanÄ±r ve mantÄ±ksÄ±z olanlar da (mesela sabit bir cismin renklerinin apayrÄ± yerlerde olmasÄ± gibi) elenir. Geri kalanlar kaydedilir ve llm'lere "bu kombinasyon olsaydÄ± kural ne olurdu, bizim girdi-Ã§Ä±ktÄ±larÄ±mÄ±zla uyumlu mu?" diyerek tetkik ettirilerek ihtimaller epeyce azaltÄ±lÄ±r. 
LLM, Ä±zgara kombinasyonlarÄ± Ã¼zerindeki mantÄ±ki kÄ±sÄ±tlarÄ± tespit Ã§Ä±karÄ±r. Bu kÄ±sÄ±tlar, MAXSAT benzeri bir mantÄ±k Ã§erÃ§evesinde continuous relaxation yÃ¶ntemiyle ihtimal vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Reasoning Layer, ihtimal vektÃ¶rlerini optimize ederek kurala en uygun kombinasyonlarÄ± Ã¼retir; yani kurallara uyan ve yÃ¼ksek olasÄ±lÄ±klÄ± Ã§Ã¶zÃ¼mler Ã¶ncelikli olarak ortaya Ã§Ä±kar.
Her bir kombinasyon embedding ile sayÄ±sal bir deÄŸere Ã§evrilir. Birbiriyle en Ã§ok alakalÄ± olan kombinasyonlar bulunup graph ile temsil edilir. Bu temsillerden hem kod hem llm'in de yardÄ±mÄ±yla beam search ve bazen de do_sample usulÃ¼yle belirlenen sayÄ±da farklÄ± dal Ã¼zerinden oluÅŸmasÄ± en makul olan kombinasyonlar tespit edilir. Bundan sonra yÃ¼kÃ¼ Llm gÃ¶ÄŸÃ¼sler ve oluÅŸan birkaÃ§ kombinasyondan ilk ikisini mantÄ±ki delillerle tercih eder.
NOT: Context penceresindeki maliyeti azaltmak iÃ§in kullanacaÄŸÄ±mÄ±z Rag veritabanÄ± usulÃ¼nde dual embedding usulÃ¼nÃ¼ yani hem embedding modelini hem de kendi asÄ±l modelimizi kullanacaÄŸÄ±z.
NOT: statik-dinamik hangi cache tipinin kullanÄ±lacaÄŸÄ± o an mevcut olan ÅŸartlara gÃ¶re belli olacak.Yani "deÄŸiÅŸmeli cache idaresi" kullanÄ±lacak.

NOT: Saat planlamasÄ± LLM insafÄ±na bÄ±rakÄ±lmayacaktÄ±r. Ä°f-else mantÄ±ÄŸÄ± tafsilatlÄ± ÅŸekilde belirlenecektir.
NOT: Feature extraction iÃ§in wavelet ve fourier analizi kullanÄ±lÄ±r. Bu, bilhassa desen tipi deÄŸiÅŸiklikleri tespit etmekte fevkaladedir.
NOT: Her bulmacanÄ±n Ã§Ã¶zÃ¼lme yÃ¼zdesi kaydedilecek.
NOT: BulmacalarÄ±n tamamlanma yÃ¼zdesi ve o ana kadar geÃ§en vakte gÃ¶re bulmacalar kolay, orta, zor gibi lakin daha detaylÄ±, belki yÃ¼zdelik zorluk ÅŸeklinde sÄ±nÄ±flandÄ±rÄ±lÄ±r. Ä°kinci devir en kolay bulmacadan en zora doÄŸru devam eder.
 NOT: Beam search veya herhangi baÅŸka tÃ¼r bir arama usulÃ¼nde maksimum adÄ±m sayÄ±sÄ± belirlenir. Mesela bu bulmacada teknik olarak 100 adÄ±m ve Ã¶tesinin olma ihtimali kesinlikle yok. Ã§ok nadir ÅŸekilde 50-60 civarÄ± olabilir(eÄŸer her hÃ¼cre bir iÅŸlem sayÄ±lÄ±rsa, ama bu sayÄ± bile fazla). KÄ±sacasÄ± bu derinlik 50'den baÅŸlatÄ±lÄ±r, Ã§Ã¶zÃ¼lebilen bulmacalarÄ±n ÅŸartlarÄ±na ve oradan edinilen intibaya gÃ¶re merhale merhale azaltÄ±lÄ±r. Tahminen 10'a kadar ineceÄŸini zannetmekteyim ama tedbiren 50'den baÅŸlayacaktÄ±r.
NOT: LLM'in neredeyse her mevzu iÃ§in dolduracak bir ÅŸablonu olacaktÄ±r. BÃ¶ylece ana mevzularda ilave dikkat kaymasÄ±ndan kaÃ§Ä±nmÄ±ÅŸ oluruz. Bu, llm'in etiketli veriler Ã¼retmesi vesaireye mugayir deÄŸildir, sadece mÃ¼mkÃ¼n olan iÅŸlerin belli ÅŸablonlarda yapÄ±lmasÄ± gerektiÄŸi kastedilmiÅŸtir.

NOT:Ä°kinci devirde iki bulmacadan hangisini Ã¶ncelikle Ã§Ã¶zmemiz gerektiÄŸini belirlerken adÄ±mlarÄ±n tamamlanma yÃ¼zdeleri(fazla ise fazla tesir), ÅŸu an harcanan sÃ¼renin ayrÄ±labilecek sÃ¼reden % kaÃ§ fazla olduÄŸu(ters tesir yapmalÄ±dÄ±r), ÅŸu anki aÅŸamada girdi-Ã§Ä±ktÄ± misallerinde en Ã§ok yÃ¼zde kaÃ§ hÃ¼crenin doÄŸru Ã§Ã¶zÃ¼lebildiÄŸi (birden fazla girdi-Ã§Ä±ktÄ± olduÄŸu gÃ¶z Ã¶nÃ¼nde bulundurulmalÄ±dÄ±r), o bulmaca iÃ§in harcanan gpu hafÄ±zasÄ±n ortalama deÄŸeri, en Ã§ok hafÄ±zayÄ± kaÃ§ saniye boyu ve kaÃ§ aÅŸamada kullandÄ±ÄŸÄ±, umumi gpu performansÄ±nda ne gibi tesirler meydana getirdiÄŸi gibi parametreler kullanÄ±larak bir formÃ¼l tÃ¼retilecektir ki bu formÃ¼lle tercih yapÄ±lacaktÄ±r.
FORMÃœL:
CadÄ±m=tamamlanan adÄ±m/toplam adÄ±m sayÄ±sÄ±
ChÃ¼cre=(1/toplam misal(Emax))her misaldeki max iÃ§in topla(Ã§Ã¶zÃ¼len hÃ¼cre sayÄ±sÄ±/toplam hÃ¼cre)
Tharcanan=harcanan sÃ¼re/azami sÃ¼re
Mortalama=(her saniye kullanÄ±lan vram toplamÄ±/ geÃ§en saniye)/azami vram(96gb)
Mmaxkomp= (EÅŸik vram Ã¼zerinde geÃ§irilen saniye/toplam sÃ¼re).(eÅŸik deÄŸer Ã¼zerinde seyreden adÄ±m sayÄ±sÄ±/toplam adÄ±m)
S(bulmaca)=((w1.CadÄ±m)+(w2.ChÃ¼cre)+(w3.Emax))-((w4.Tharcanan)+(w5.Mortalama)+(w6.Mmaxkompl))





NOT: Entropi hesabÄ± ÅŸunlar iÃ§in yapÄ±labilir:  entropi formÃ¼lÃ¼ne sokulur, toplamda entropisi dÃ¼ÅŸÃ¼k olanÄ±kimin  dÃ¼ÅŸÃ¼kse Ã§Ã¶zmeye ondan baÅŸlanÄ±r. 


BaÅŸka bir misalde Ã§Ä±ktÄ± kombinasyonlarÄ±nÄ±n girdiyle farkÄ±(mevki farkÄ± da dahil yÃ¼zdelik olarak Ã¶lÃ§Ã¼lÃ¼p entropiye sokulur ve dÃ¼ÅŸÃ¼k Ã§Ä±kan kombinasyonlar Ã¶nceliklendirilir. Ã‡Ã¼nkÃ¼ aÅŸÄ±rÄ± deÄŸiÅŸim daha nadir gÃ¶rÃ¼lÃ¼r. Sonradan bu kÃ¼Ã§Ã¼k entropililer beam search aramasÄ±nda birbirine yakÄ±n dallarda Ã§Ä±kacaktÄ±r. Aramalar kÃ¼Ã§Ã¼k farklardan bÃ¼yÃ¼k farklara doÄŸru olmalÄ±dÄ±r.
Kombinasyon motoru:
Bu motor girdi-Ã§Ä±ktÄ±nÄ±n ebatlarÄ±na gÃ¶re farklÄ± davranÄ±r. Ebatlar aynÄ± ise deÄŸiÅŸimler tespit edilir ve girdiyi Ã§Ä±ktÄ±ya yaklaÅŸtÄ±ran kombinasyonlar Ã¼retilir. Mesela girdideki sarÄ±lar kÄ±rmÄ±zÄ± oluyorsa motor o sarÄ± renklerin kÄ±rmÄ±zÄ±ya farklÄ± kombinasyonlarda Ã§evrilmiÅŸ Ä±zgara halini Ã¼retir. Mesela tek bir kare iki adÄ±m ileri gitmiÅŸse motor sadece bir kare ileri gidilen ve iki kare ileri gidilen kombinasyonu bulunca iÅŸ biter. 
BaÅŸka bir misalde nesne tespiti ve simetri tespiti yaparken daha Ã¶nce izah ettiÄŸimiz "gÃ¶z"Ã¼n gÃ¶rdÃ¼ÄŸÃ¼ hÃ¼crelerdeki renklerin toplam gÃ¶rÃ¼len hÃ¼credeki oranlarÄ± Ã§Ä±kartÄ±lÄ±r, entropi dÃ¼ÅŸÃ¼kse orada az ÅŸekil vardÄ±r, fazlaysa Ã§ok ÅŸekil vardÄ±r, desen olma ihtimali de artar. Filtrenin yeri ve ebatÄ± tespitlere gÃ¶re deÄŸiÅŸtirilir ve esas nesneler ve desenler tespit edilir. Åunu sÃ¶ylemek lazÄ±mdÄ±r ki varsayÄ±lan olarak aynÄ± renklerin kenarlardan beraber olduklarÄ± hÃ¼creler nesnedir, bunun ihtimali yÃ¼zde yÃ¼z alÄ±nÄ±r ama parÃ§alanabilme ihtimali de yÃ¼zde yÃ¼zdÃ¼r. Bu aynÄ± bir ekmeÄŸin istenilen yerden ikiye bÃ¶lÃ¼nebilmesi gibidir. Ä°stersen 3'e dÃ¶rde bÃ¶lebilirsin. Bunlardan hangisinin doÄŸru olduÄŸu girdi Ã§Ä±ktÄ±daki deÄŸiÅŸimlerden tespit edilir, yani oranlar buna gÃ¶re dinamik olarak ayarlanÄ±r, entropi dÃ¼ÅŸÃ¼nce varsayÄ±lan olarak baskÄ±n Ã§Ä±kan ihtimaller kalÄ±r.


NOT: Evvela tÃ¼m bulmacalar hakkÄ±nda ilk sql tablolarÄ± Ã§Ã¶zÃ¼m yapmadan mÃ¼mkÃ¼n olan en iyi ÅŸekilde doldurulur. Ã‡Ã¶zÃ¼len bulmacalarÄ±n eÄŸitim faydasÄ± olmayacaÄŸÄ±, sadece Rag'Ä± zenginleÅŸtireceÄŸi iÃ§in evvela ana test dosyasÄ± yani asÄ±l bulmacalar Ã§Ã¶zÃ¼lÃ¼r. hepsine bir kez bakÄ±ldÄ±ktan sonra Ã§Ã¶zÃ¼lenler kaydedilirken Ã§Ã¶zÃ¼lemeyenler iÃ§in fikir versin diye bize Ã¶nceden verilmiÅŸ dosyalar Ã§Ã¶zÃ¼lÃ¼r, Rag zenginleÅŸir. Her 10 bulmacada bir(sayÄ± deÄŸiÅŸebilir) en kolay bulmacalar Ã§Ã¶zÃ¼lmeye Ã§alÄ±ÅŸÄ±lÄ±r. Ä°kinci devirden sonra yine eski dosyalar Ã§Ã¶zÃ¼lmeye devam edilir.  

NOT: Bulmaca Ã§Ã¶zÃ¼lÃ¼rken evvela girdi Ã§Ä±ktÄ± misallerine bakÄ±lÄ±r. Kural ve kod fonksiyonu hakkÄ±nda kesinlikle belli olan kural ve kÄ±sÄ±tlamalar llm tarafÄ±ndan uygun dille(kod, arkdil ifadesi, metin) ifade edilir.Daha sonra kendi 10 tahminini ifade eder. Bunlar kod ve kombinasyon motoruna aktarÄ±lÄ±r. Her iki motor da bu ifadelere istinaden beam search ile en muhtemel varyasyonlarÄ± Ã¼retir ve kaydeder. Her 10 Ã¼retimde bir llm'in tetkikine muhatap olur. Bu ÅŸekilde sÃ¼rekli iyileÅŸtirme olur. Kod varyasyonlarÄ± girdiye uygulanarak Ã§Ä±ktÄ±yÄ± verip vermediÄŸi kontrol edilir. HatalÄ± olanlar elenir ve neden hata olduÄŸu llm tarafÄ±ndan deÄŸerlendirilir. Ortaya yeni bir kÄ±sÄ±t veya kaide Ã§Ä±karsa bu da ilave edilir. EÄŸer doÄŸru bir kod Ã§Ä±kmÄ±ÅŸ ise diÄŸer misal girdi-Ã§Ä±ktÄ±ya geÃ§ilir ve ilk olarak bu kod denenir. Bunda da doÄŸru Ã§alÄ±ÅŸÄ±rsa teste tatbik edilip cevap kaydedilir. EÄŸer yanlÄ±ÅŸ Ã§Ä±kmÄ±ÅŸsa yine tetkikat ile geliÅŸim devam eder. Ä°lk girdi-Ã§Ä±ktÄ±ya uyup da ikinciye uymayan olursa sebebi llm tarafÄ±ndan bulunmaya Ã§alÄ±ÅŸÄ±lÄ±r, yeni kÄ±sÄ±tlar ile arama dÃ¶ngÃ¼sÃ¼ devam eder. DoÄŸru Ã§alÄ±ÅŸmayan Ã¼retimler hemen silinmeyip doÄŸruluk yÃ¼zdesi kaydedilir ve arama yapÄ±lacaÄŸÄ± zaman yÃ¼ksek yÃ¼zdelikli ihtimallere Ã¶ncelik vermek kaydÄ±yla dÃ¼ÅŸÃ¼k ihtimalliler de bir dereceye kadar gÃ¶z Ã¶nÃ¼nde bulundurulmuÅŸ olur.


âœ…NOT: LLM, arama uzayÄ±nÄ± daraltÄ±rken ÅŸablon olarak "bu ispatlÄ±" "bu aÅŸikardÄ±r" "tahminimce" "Ã¶yle gÃ¶zÃ¼kÃ¼yor ki" gibi etiketler kullanÄ±r.
Ä°spatlÄ± ve aÅŸikar gibi etiketlerin olduÄŸu kÄ±sÄ±mlar doÄŸrudan doÄŸruya kÄ±sÄ±t fonksiyonuna dahil edilir, tahminler ise kÄ±sÄ±t namzeti haline getirilip saklanÄ±r. Lakin etiket sisteminin henÃ¼z ayrÄ±ntÄ±lÄ± olarak belirlenmediÄŸi ve bu fikrin deÄŸiÅŸebileceÄŸi gÃ¶z Ã¶nÃ¼nde bulundurulmalÄ±dÄ±r.

NOT:Kod parÃ§alarÄ±nÄ±n toplam Ã§Ã¶zÃ¼len bulmacalarda kullanÄ±lma yÃ¼zdeleri Ã§Ä±kartÄ±lÄ±r ve fazla ihtimali olanlarÄ±n olduÄŸu programlar evvelce kullanÄ±lÄ±r.




NOT: Modelin uzayÄ±na yakÄ±n olmayan kelimelerden analoji yaparak bulmacayÄ± Ã§eÅŸitli ÅŸekillere veya herhangi bir ÅŸeye benzetecek. Buna has bir katman olacak.
NOT: LLM Ã¼retilecek dÃ¶nÃ¼ÅŸÃ¼m kodunda hangi parÃ§alarÄ±n kesin olarak var olacaÄŸÄ±nÄ± da belirler ki kod ihtimalleri azalsÄ±n, sonra deÄŸiÅŸken olanlar denenir. EÄŸer Llm onlardan birinin de olmasÄ± gerektiÄŸini ispatlarsa o da sabitlenir.


NOT: Katman belirleme iÅŸleri basitleÅŸtirilmiÅŸtir. Evvela girdi Ä±zgarasÄ±ndaki farklÄ± renkler aynÄ± renkler kÃ¼me olacak ÅŸekilde rastgele katmanlara atanÄ±r, sonra aynÄ±sÄ± Ã§Ä±ktÄ±ya yapÄ±lÄ±r. Girdideki her eleman mutlaka Ã§Ä±ktÄ±da da var olacakmÄ±ÅŸ gibi dÃ¼ÅŸÃ¼nÃ¼lÃ¼r yani aynÄ± katmanlarda dururlar. Hareket, silinme gibi haller bu teoriye uymayan bulmacalarda olabilir. Buna gÃ¶re if else kurulur. Ã‡Ä±ktÄ± ekranÄ±nda asÄ±l gÃ¶zÃ¼ken renk kÃ¼meleri de katmanlara atanÄ±nca Ã¼stten gÃ¶zÃ¼kÃ¼p gÃ¶zÃ¼kmediÄŸine gÃ¶re if else yapÄ±sÄ±yla denetlenir ve gÃ¶zÃ¼kmÃ¼yorsa Ã¼st katmana atanÄ±r. Bu rastgele iÅŸlemler bittikten sonra katmanlar birbirine olabildiÄŸince yakÄ±nlaÅŸtÄ±rÄ±lÄ±r. Bu sayede kimin Ã¶nde, kimin arkada olduÄŸu belli olur.


NOT:GE (Grammatical Evolution) usulunde kod parÃ§acÄ±klarÄ± sayÄ± dizileriyle temsil edilip oluÅŸturulan dil kuralÄ±na gÃ¶re Ã§eÅŸitli kombinasyonlar denenerek hem hafÄ±za yÃ¼kÃ¼ azaltÄ±lÄ±r hem de bazÄ± avantajlarÄ± vardÄ±r. Dsl ise bir kod havuzudur. Biz ise bir iliÅŸki yumaÄŸÄ± havuzu yazacaÄŸÄ±z. Burada deÄŸiÅŸime tabi olabilen ÅŸeyler, deÄŸiÅŸimle alakalÄ± olabilenler, alaka seviyeleri gibi Ã§eÅŸitli ifadeler yer alÄ±r. her ifade bir sayÄ± ile temsil edilir. Ã‡eÅŸitli kÄ±sÄ±tlamalardan sonra bu iliÅŸki yumaÄŸÄ±nÄ±n muhtemel kombinasyonlarÄ± hesaplanÄ±nca hipotez oluÅŸturmak iÃ§in doÄŸrudan hazÄ±r bir defter oluÅŸur. ArtÄ±k Llm tercihiyle hepsi sÄ±rayla denenirse Ã§Ã¶zÃ¼me mutlaka ulaÅŸÄ±lÄ±r. Yani iliÅŸki yumaÄŸÄ±, kod yumaÄŸÄ± ve Ä±zgara yumaÄŸÄ±yla Ã¼Ã§ ayrÄ± yumak kombinasyonlarÄ± hesaplanÄ±r.


NOT: Izgara ebatlarÄ± dahi bulmacaya dahildir, bu da iliÅŸki yumaÄŸÄ±yla tespit edilir. Ã‡Ã¼nkÃ¼ Ã§Ã¶zdÃ¼ÄŸÃ¼m bulmacalardan Ã§ok farklÄ± Ä±zgara ebatlarÄ± tespit edilmiÅŸtir ve bu ebatlarÄ±n bulmaca Ã§Ã¶zÃ¼lmeden belirlenmesi mÃ¼mkÃ¼n deÄŸildir.
NOT:Eminlik seviyesini hesaplama usulÃ¼ bulalÄ±m. En basitinden deriz ki , her etiketli bÃ¶lÃ¼m iÃ§in Ã¼retilmiÅŸ tokenler yÃ¼zde kaÃ§ ihtimalle Ã¼retildiyse hepsini toplar ve bÃ¶lÃ¼m sayÄ±sÄ±na bÃ¶leriz. Veya Ã§arpÄ±mlÄ± bir iÅŸ yaparÄ±z. Ã‡Ä±kan yÃ¼zdelik o bÃ¶lÃ¼mdeki emniyet katsayÄ±sÄ±dÄ±r. Her bÃ¶lÃ¼mÃ¼n emniyet katsayÄ±sÄ±nÄ± da aynÄ± iÅŸlemlere tabii tutup tÃ¼m Ã§Ä±ktÄ±nÄ±n emniyetini hesaplarÄ±z.

NOT:Rag yerleÅŸtirme usulÃ¼nde kosinÃ¼s benzerliÄŸi deÄŸil kosinÃ¼s mesafesi kullanmalÄ±yÄ±z.

NOT: LLM'in hakikaten kendinden emin olduÄŸunu anlamak iÃ§in Ã¼rettiÄŸi metin iÃ§indeki bazÄ± kelimelerin manasÄ±, neden o ÅŸekilde kullanÄ±ldÄ±ÄŸÄ± ayrÄ± bir prompt olarak, teftiÅŸ dÃ¶ngÃ¼sÃ¼nde eklenir.Bu sorular manuel hazÄ±rlanabileceÄŸi gibi zor da olsa modelin kendisi tarafÄ±ndan kÄ±sÄ±r dÃ¶ngÃ¼ye dÃ¼ÅŸme ihtimali olsa da Ã¼retilebilir. Soru sorulabileceÄŸi gibi ona aslÄ±nda yanlÄ±ÅŸ olan bir ÅŸey doÄŸruymuÅŸ gibi sÃ¶ylenebilir ve Ã§Ä±ktÄ±ya gÃ¶re eminlik seviyesine karar verilir.

NOT: SÄ±radan bir Llm'de temprature ayarlamasÄ± yapÄ±ldÄ±ÄŸÄ±nda deÄŸiÅŸtirilen ÅŸey rastgeleliktir. Halbuki bize doÄŸru ÅŸeyler lazÄ±mdÄ±r. Bu yÃ¼zden bu katsayÄ± arttÄ±rÄ±ldÄ±ÄŸÄ±nda rastgelelik deÄŸil Ã§Ä±ktÄ±nÄ±n hesaplandÄ±ÄŸÄ± usul sayÄ±sÄ± fazlalaÅŸtÄ±rÄ±lÄ±r ve en doÄŸru Ã§Ä±ktÄ± tercih edilir.
Åu usul daha da makul olabilir: doÄŸruluk oranÄ±, alaka gibi kendi kuracaÄŸÄ±mÄ±z kÄ±staslara gÃ¶re model cevabÄ± deÄŸerlendirilir ve eÄŸer bir kÄ±sÄ±m kÃ¶tÃ¼ gÃ¶rÃ¼lÃ¼rse o kÄ±sma kadarki dal aynÄ± bÄ±rakÄ±lÄ±p sonraki adÄ±mda Ã¶nceden geÃ§tiÄŸimiz daldan geÃ§mek yerine baÅŸka yakÄ±n ihtimalli bir daldan geÃ§eriz, bu cevap da anÄ±nda deÄŸerlendirilir. Bu sayede Ã¼retim-kontrol eÅŸ zamanlÄ± ÅŸekilde gerÃ§ekleÅŸtirilir. 

NOT: Tahmini harcanacak sÃ¼re non-linear regresyon ile profesyonel ÅŸekilde modellenir.

NOT: Modelin harici multi-head'lerinin her biri iÃ§in ayrÄ± sistem talimatÄ± tanÄ±mlanÄ±r. Etiketli bir Ã§Ä±ktÄ± Ã¼retildiÄŸi zaman Ã§Ä±ktÄ± ile talimat arasÄ±ndaki ve talimata en yakÄ±n 100 kelime arasÄ±ndaki matematiksel benzerlik hesaplanÄ±r. Hangi modelin talimatÄ± en benzer Ã§Ä±kÄ±yorsa Ã§Ä±ktÄ± ona yÃ¶nlendirilir.


NOT: Modelimiz lora usuluyle edebi metinlerle eÄŸitilir Ã§Ã¼nkÃ¼ aslÄ±nda dÄ±ÅŸtan bakÄ±nca dÃ¼nya nesnelerine benzeyen bulmacalar da vardÄ±r. Modele png dosyasÄ± verilir ve bu resimde gerÃ§ek hayatta var olan bir ÅŸekil gÃ¶rÃ¼yor musun diye sorulur. Bunun hakkÄ±nda hikaye yaz denir, bulmacadaki nesnenin Ã¶zellikleriyle birebir uyumlu bir hikaye olsun denir, mesela kare bir kurbaÄŸa ise "kurbaÄŸanÄ±n burnundaki x hÃ¼cresi..." dahi denebilir.


NOT:promptun iÃ§inde uzun cevap istenir ve eÄŸer minimum token doÄŸrudan belirlenirse o direk kabul edilir, deÄŸiÅŸkene atanmÄ±ÅŸ olan bu deÄŸer min new token olarak kodda doÄŸrudan kullanÄ±lÄ±r.Sadece uzun olsun denilirse baÅŸka bir batch tarafÄ±ndan durumun getirdiÄŸi ÅŸartlara gÃ¶re lakin bol keseden belirlensin.

NOT:Model inference ederken her bir cÃ¼mle bitince otomatik olarak batch count miktarÄ± artar, yani ilk cÃ¼mleden sonraki cÃ¼mleden mesela 10 cÃ¼mle daha Ã¼retilir, sonra diÄŸer cÃ¼mle en muhtemele gÃ¶re her biri iÃ§in mi bir tane hesaplansÄ±n. Yani hala 10 ayrÄ± mesaj var. Bunlar bir kontrole tabii tutulur ve en iyi tek mesaj seÃ§ilir. Sonra yine 10â€™luk Ã¼retim yapÄ±lÄ±r, sonraki cÃ¼mleyle onlarÄ±n da tetkiki yapÄ±lÄ±r.